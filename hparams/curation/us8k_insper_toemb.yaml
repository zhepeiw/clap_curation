# File              : zeroshot.yaml
# Author            : Zhepei Wang <zhepeiw2@illinois.edu>
# Date              : 27.01.2022
# Last Modified Date: 01.12.2022
# Last Modified By  : Zhepei Wang <zhepeiw2@illinois.edu>


seed: 2022
__set_seed: !apply:torch.manual_seed [!ref <seed>]
np_rng: !new:numpy.random.RandomState [!ref <seed>]


time_stamp: placeholder
experiment_name: audioset_insper_curation
output_base: /mnt/data2/zhepei/outputs/uclap/mm_zs
output_folder: !ref <output_base>/<time_stamp>_seed_<seed>+<experiment_name>
train_log: !ref <output_folder>/train_log.txt
save_folder: !ref <output_folder>/save


# Training parameters
number_of_epochs: 100
audio_batch_size: 32
text_batch_size: 32
num_workers: 8
temp_tau: 0.07
text_max_length: 100

# dataset
sample_rate: 44100
train_duration: 5.0
data_folder: "/mnt/data2/Sound Sets/UrbanSound8K/UrbanSound8K"
selected_folds: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
text_pathfile: "/home/zhepei/workspace/microsoft_clap/CLAP/unsupervised_curation/insper_train_dev.csv"

audio_dataset: !new:dataset.curation_dataset.UrbanSoundDataset
  root_dir: !ref <data_folder>
  selected_folds: !ref <selected_folds>
  sr: !ref <sample_rate>
  duration: !ref <train_duration>

audio_dataloader_opts:
  batch_size: !ref <audio_batch_size>
  num_workers: !ref <num_workers>
  shuffle: False
  drop_last: False

text_dataset: !new:dataset.curation_dataset.InsperCaptionDataset
  df_path: !ref <text_pathfile>

text_dataloader_opts:
  batch_size: !ref <text_batch_size>
  num_workers: !ref <num_workers>
  shuffle: False
  drop_last: False

# Experiment params
use_maxacc_ep: False
use_minloss_ep: False
auto_mix_prec: False # Set it to True for mixed precision


# Feature parameters
window_size: 1024
hop_size: 320
mel_bins: 64
fmin: 50
fmax: 14000
aud_emb_classes_num: 527

# Number of classes
emb_norm_type: bn
aud_emb_dim: 2048
txt_emb_dim: 768
shared_emb_dim: 1024

# Functions
clap: !new:models.microsoft_clap.CLAP
    audioenc_name: Cnn14
    sample_rate: !ref <sample_rate>
    window_size: !ref <window_size>
    hop_size: !ref <hop_size>
    mel_bins: !ref <mel_bins>
    fmin: !ref <fmin>
    fmax: !ref <fmax>
    classes_num: !ref <aud_emb_classes_num>
    out_emb: !ref <aud_emb_dim>
    text_model: bert-base-uncased
    transformer_embed_dim: !ref <txt_emb_dim>
    d_proj: !ref <shared_emb_dim>

txt_tokenizer: !apply:transformers.AutoTokenizer.from_pretrained
    pretrained_model_name_or_path: bert-base-uncased


modules:
  clap: !ref <clap>
    # compute_features: !ref <compute_features>
    # mean_var_norm: !ref <mean_var_norm>


compute_cost: !new:losses.LogSoftmaxWithProbWrapper
    loss_fn: !new:torch.nn.Identity

acc_metric: !name:speechbrain.utils.Accuracy.AccuracyStats

opt_class: null

epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter
    limit: !ref <number_of_epochs>

datapoint_counter: !new:utils.DatapointCounter

# Logging + checkpoints
checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer
    checkpoints_dir: !ref <save_folder>

recoverables:
    datapoint_counter: !ref <datapoint_counter>

clap_ckpt_path: '/mnt/data2/zhepei/model_weights/CLAP/CLAP_weights_2022.pth'

ssl_checkpoints_dir: null
# ssl_checkpointer: null
ssl_checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer
    checkpoints_dir: !ref <ssl_checkpoints_dir>
    recoverables:
      clap: !ref <clap>
      epoch_counter: !ref <epoch_counter>

aud_svpth: !ref <save_folder>/audio_us8k_embeddings.npy
txt_svpth: !ref <save_folder>/text_insper_embeddings.npy

train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger
    save_file: !ref <train_log>

# wandb
use_wandb: False
train_log_frequency: 20
wandb_logger_fn: !name:utils.MyWandBLogger
    initializer: !name:wandb.init
    entity: CAL
    project: cssl_sound
    name: !ref <time_stamp>+seed_<seed>+<experiment_name>
    dir: !ref <output_folder>
    reinit: True
    yaml_config: hparams/curation/mm_audioset_insper_toemb.yaml
    resume: False
